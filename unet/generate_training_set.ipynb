{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "# Change directory to main repository directory in order to install modules\n",
    "os.chdir(f\"{os.environ['HOME']}/Code/ExoTiC-NEAT-training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import fits\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations = \"/data/typhon2/hattie/jwst/soss_simulations/10000_soss_sims_randomised_target.h5\"\n",
    "\n",
    "simulation_list = []\n",
    "clean_simulation_list = []\n",
    "contaminant_simulation_list = []\n",
    "with h5py.File(simulations, \"r\") as f:\n",
    "    for key in f.keys():\n",
    "        if key.startswith(\"data\"):\n",
    "            simulation_list.append(f[key][:])\n",
    "        if key.startswith(\"clean\"):\n",
    "            clean_simulation_list.append(f[key][:])\n",
    "        if key.startswith(\"contaminant\"):\n",
    "            contaminant_simulation_list.append(f[key][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation array shape: (10000, 256, 2048)\n",
      "Clean simulation array shape: (10000, 256, 2048)\n",
      "Contaminant simulation array shape: (10000, 256, 2048)\n"
     ]
    }
   ],
   "source": [
    "simulation_array = np.array(simulation_list)\n",
    "clean_simulation_array = np.array(clean_simulation_list)\n",
    "contaminant_simulation_array = np.array(contaminant_simulation_list)\n",
    "print(f\"Simulation array shape: {simulation_array.shape}\")\n",
    "print(f\"Clean simulation array shape: {clean_simulation_array.shape}\")\n",
    "print(f\"Contaminant simulation array shape: {contaminant_simulation_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap: 35.02%\n",
      "Zero: 10.45%\n",
      "No overlap: 54.53%\n"
     ]
    }
   ],
   "source": [
    "def get_class_indeces(data_array, label_array, clean_array):\n",
    "    overlap_index = []\n",
    "    zero_index = []\n",
    "    no_overlap_index = []\n",
    "\n",
    "    for index, (data_slice, label_slice, clean_slice) in enumerate(zip(data_array, label_array, clean_array)):\n",
    "        max_data = data_slice.max()\n",
    "        max_label = label_slice.max()\n",
    "        max_clean = clean_slice.max()\n",
    "\n",
    "        if max_label != 0:\n",
    "            if max_data > max_clean:\n",
    "                overlap_index.append(index)\n",
    "            else:\n",
    "                no_overlap_index.append(index)\n",
    "        else:\n",
    "            zero_index.append(index)\n",
    "\n",
    "    return overlap_index, zero_index, no_overlap_index\n",
    "\n",
    "overlap, zero, no_overlap = get_class_indeces(simulation_array, contaminant_simulation_array, clean_simulation_array)\n",
    "\n",
    "print(f\"Overlap: {(len(overlap) / len(simulation_array)) * 100}%\")\n",
    "print(f\"Zero: {(len(zero) / len(simulation_array)) * 100}%\")\n",
    "print(f\"No overlap: {(len(no_overlap) / len(simulation_array)) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overlap) + len(zero) + len(no_overlap) == len(simulation_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split simulations by class using index lists\n",
    "overlap_simulations = simulation_array[overlap]\n",
    "zero_simulations = simulation_array[zero]\n",
    "no_overlap_simulations = simulation_array[no_overlap]\n",
    "\n",
    "overlap_labels = contaminant_simulation_array[overlap]\n",
    "zero_labels = contaminant_simulation_array[zero]\n",
    "no_overlap_labels = contaminant_simulation_array[no_overlap]\n",
    "\n",
    "overlap_clean = clean_simulation_array[overlap]\n",
    "zero_clean = clean_simulation_array[zero]\n",
    "no_overlap_clean = clean_simulation_array[no_overlap]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap simulations shape: (3502, 256, 2048)\n",
      "Zero simulations shape: (1045, 256, 2048)\n",
      "No overlap simulations shape: (5453, 256, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overlap simulations shape: {overlap_simulations.shape}\")\n",
    "print(f\"Zero simulations shape: {zero_simulations.shape}\")\n",
    "print(f\"No overlap simulations shape: {no_overlap_simulations.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced simulations shape: (3000, 256, 2048)\n",
      "Balanced labels shape: (3000, 256, 2048)\n",
      "Balanced clean shape: (3000, 256, 2048)\n"
     ]
    }
   ],
   "source": [
    "# create balanced simulation dataset using 500 of each\n",
    "slice_index = 1000\n",
    "balanced_simulations = np.concatenate((overlap_simulations[:slice_index], zero_simulations[:slice_index], no_overlap_simulations[:slice_index]))\n",
    "balanced_labels = np.concatenate((overlap_labels[:slice_index], zero_labels[:slice_index], no_overlap_labels[:slice_index]))\n",
    "balanced_clean = np.concatenate((overlap_clean[:slice_index], zero_clean[:slice_index], no_overlap_clean[:slice_index]))\n",
    "\n",
    "print(f\"Balanced simulations shape: {balanced_simulations.shape}\")\n",
    "print(f\"Balanced labels shape: {balanced_labels.shape}\")\n",
    "print(f\"Balanced clean shape: {balanced_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap: 33.33333333333333%\n",
      "Zero: 33.33333333333333%\n",
      "No overlap: 33.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "# verify that the balanced dataset is balanced\n",
    "\n",
    "def calculate_class_percentage(data_array, label_array, clean_array):\n",
    "    trace_overlap_count = 0\n",
    "    zero_count = 0\n",
    "    for data_slice, label_slice, clean_slice in zip(data_array, label_array, clean_array):\n",
    "        max_data = data_slice.max()\n",
    "        max_label = label_slice.max()\n",
    "        max_clean = clean_slice.max()\n",
    "\n",
    "        if max_label != 0:\n",
    "            if max_data > max_clean:\n",
    "                trace_overlap_count += 1\n",
    "        else:\n",
    "            zero_count += 1\n",
    "        \n",
    "        no_overlap = len(data_array) - trace_overlap_count - zero_count\n",
    "    return trace_overlap_count / len(data_array), zero_count / len(data_array), no_overlap / len(data_array)\n",
    "\n",
    "overlap, zero, no_overlap = calculate_class_percentage(balanced_simulations, balanced_labels, balanced_clean)\n",
    "\n",
    "print(f\"Overlap: {overlap * 100}%\")\n",
    "print(f\"Zero: {zero * 100}%\")\n",
    "print(f\"No overlap: {no_overlap * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data points: 2400\n",
      "Number of validation data points: 300\n",
      "Number of test data points: 300\n"
     ]
    }
   ],
   "source": [
    "# split data into 80:10:10 % train:val:test\n",
    "number_data_points = balanced_simulations.shape[0]\n",
    "number_train_points = int(0.8 * number_data_points)\n",
    "number_validation_points = int(0.1 * number_data_points)\n",
    "number_test_points = number_data_points - number_train_points - number_validation_points\n",
    "\n",
    "train_simulations = balanced_simulations[:number_train_points]\n",
    "validation_simulations = balanced_simulations[number_train_points:number_train_points + number_validation_points]\n",
    "test_simulations = balanced_simulations[number_train_points + number_validation_points:]\n",
    "\n",
    "train_clean_simulations = balanced_clean[:number_train_points]\n",
    "validation_clean_simulations = balanced_clean[number_train_points:number_train_points + number_validation_points]\n",
    "test_clean_simulations = balanced_clean[number_train_points + number_validation_points:]\n",
    "\n",
    "train_contaminant_simulations = balanced_labels[:number_train_points]\n",
    "validation_contaminant_simulations = balanced_labels[number_train_points:number_train_points + number_validation_points]\n",
    "test_contaminant_simulations = balanced_labels[number_train_points + number_validation_points:]\n",
    "\n",
    "print(f\"Number of training data points: {number_train_points}\")\n",
    "print(f\"Number of validation data points: {number_validation_points}\")\n",
    "print(f\"Number of test data points: {number_test_points}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data_dir = \"/data/typhon2/hattie/jwst/soss_simulations/training_data/\"\n",
    "# for data_set, name in zip([train_simulations, validation_simulations, test_simulations], [\"train\", \"validation\", \"test\"]):\n",
    "#     for index, spectra in enumerate(data_set):\n",
    "#         plt.imsave(f\"{training_data_dir}/{name}/data/spectra_{index}.png\", spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data_set, name in zip([train_clean_simulations, validation_clean_simulations, test_clean_simulations], [\"train\", \"validation\", \"test\"]):\n",
    "#     for index, spectra in enumerate(data_set):\n",
    "#         plt.imsave(f\"{training_data_dir}/{name}/clean/spectra_{index}.png\", spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data_set, name in zip([train_contaminant_simulations, validation_contaminant_simulations, test_contaminant_simulations], [\"train\", \"validation\", \"test\"]):\n",
    "#     for index, spectra in enumerate(data_set):\n",
    "#         plt.imsave(f\"{training_data_dir}/{name}/contaminant/spectra_{index}.png\", spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (3, 2400, 256, 2048)\n",
      "Validation data shape: (3, 300, 256, 2048)\n",
      "Test data shape: (3, 300, 256, 2048)\n"
     ]
    }
   ],
   "source": [
    "training_data = np.asarray([train_simulations, train_clean_simulations, train_contaminant_simulations])\n",
    "validation_data = np.asarray([validation_simulations, validation_clean_simulations, validation_contaminant_simulations])\n",
    "test_data = np.asarray([test_simulations, test_clean_simulations, test_contaminant_simulations])\n",
    "\n",
    "print(f\"Training data shape: {training_data.shape}\")\n",
    "print(f\"Validation data shape: {validation_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"unet/data/training_data_3000.npy\", training_data)\n",
    "np.save(\"unet/data/validation_data_3000.npy\", validation_data)\n",
    "np.save(\"unet/data/test_data_3000.npy\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwst-C1x4mLXo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
